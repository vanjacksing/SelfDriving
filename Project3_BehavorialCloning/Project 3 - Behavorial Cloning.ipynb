{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, Cropping2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "driving_logs = glob(\"driving_log*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gather logs from all datasets\n",
    "logs_df = [pd.read_csv(log, header=None) for log in driving_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22812.000000</td>\n",
       "      <td>22812.000000</td>\n",
       "      <td>22812.000000</td>\n",
       "      <td>2.281200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.024412</td>\n",
       "      <td>0.820748</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>2.925521e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.134234</td>\n",
       "      <td>0.296372</td>\n",
       "      <td>0.013991</td>\n",
       "      <td>3.534222e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.851782e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.041394</td>\n",
       "      <td>0.670782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.010205e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.018979e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.019028e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.845074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583636</td>\n",
       "      <td>3.078679e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  3             4             5             6\n",
       "count  22812.000000  22812.000000  22812.000000  2.281200e+04\n",
       "mean      -0.024412      0.820748      0.000478  2.925521e+01\n",
       "std        0.134234      0.296372      0.013991  3.534222e+00\n",
       "min       -1.000000      0.000000      0.000000  1.851782e-07\n",
       "25%       -0.041394      0.670782      0.000000  3.010205e+01\n",
       "50%        0.000000      1.000000      0.000000  3.018979e+01\n",
       "75%        0.000000      1.000000      0.000000  3.019028e+01\n",
       "max        0.845074      1.000000      0.583636  3.078679e+01"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate driving logs\n",
    "driving_log = pd.concat(logs_df)\n",
    "# Process image paths (get rid of backslashes) to get only file names \n",
    "driving_log.iloc[:, 0] = driving_log.iloc[:, 0].str.replace(\"\\\\\", \"/\").str.split(\"/\").str[-1]\n",
    "driving_log.iloc[:, 1] = driving_log.iloc[:, 1].str.replace(\"\\\\\", \"/\").str.split(\"/\").str[-1]\n",
    "driving_log.iloc[:, 2] = driving_log.iloc[:, 2].str.replace(\"\\\\\", \"/\").str.split(\"/\").str[-1]\n",
    "# Feature dataset\n",
    "features = driving_log.iloc[:, [0, 1, 2, 3]]\n",
    "# See stats for driving telemetry. First column is steering angle\n",
    "driving_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Frames from central camera\n",
    "X_center, y_center = features.iloc[:, 0].values, features.iloc[:, 3].values\n",
    "# Frames from left camera with augmented steering angle\n",
    "X_left, y_left = features.iloc[:, 1].values, features.iloc[:, 3].values + 0.07\n",
    "# Frames from right camera with augmented angle\n",
    "X_right, y_right = features.iloc[:, 2].values, features.iloc[:, 3].values - 0.07\n",
    "# Resulting dataset\n",
    "X, y = np.concatenate([X_center, X_left, X_right]), np.concatenate([y_center, y_left, y_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68436,), (68436,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset has now 68436 images\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "#    X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "BATCH_SIZE=32 # number of samples in a batch\n",
    "EPOCH_STEPS = 2*X_train.shape[0]//BATCH_SIZE # number of batches for 1 epoch\n",
    "EPOCHS = 5 # number of epochs\n",
    "VALID_STEPS = 2*X_test.shape[0]//BATCH_SIZE # amount of validation batches\n",
    "\n",
    "# Data generator. \n",
    "# For each batch takes BATCH_SIZE//2 original images and the same amount\n",
    "# of flipped left to right images with negative steering angles\n",
    "\n",
    "def datagen(X, y, batch_size=BATCH_SIZE):\n",
    "    num_samples = X.shape[0]\n",
    "    while 1:\n",
    "        shuffle(X, y)\n",
    "        for offset in range(0, num_samples, batch_size//2):\n",
    "            files = X[offset:offset+batch_size//2]\n",
    "            angles = y[offset:offset+batch_size//2]\n",
    "            image_batch = []\n",
    "            angle_batch = []\n",
    "            for f, a in zip(files, angles):\n",
    "                image = cv2.imread('IMG/' + f)\n",
    "                # Resize original image\n",
    "                small = cv2.resize(image, (240, 120))\n",
    "                # Convert image to YUV color space\n",
    "                image = cv2.cvtColor(small, cv2.COLOR_BGR2YUV)\n",
    "                image_batch.append(image)\n",
    "                image_batch.append(np.fliplr(image))\n",
    "                angle_batch.append(float(a))\n",
    "                angle_batch.append(float(-a))\n",
    "                \n",
    "            yield shuffle(np.array(image_batch), np.array(angle_batch))\n",
    "train_gen = datagen(X_train, y_train)\n",
    "valid_gen = datagen(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3421/3421 [==============================] - 134s - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 2/5\n",
      "3421/3421 [==============================] - 127s - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 3/5\n",
      "3421/3421 [==============================] - 127s - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 4/5\n",
      "3421/3421 [==============================] - 127s - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 5/5\n",
      "3421/3421 [==============================] - 127s - loss: 0.0105 - val_loss: 0.0097\n"
     ]
    }
   ],
   "source": [
    "# Model is based on Nvidia end-to-end self-driving network architecture\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(120,240,3)))\n",
    "model.add(Cropping2D(cropping=((45, 15), (0, 0))))\n",
    "model.add(Conv2D(24, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(Conv2D(36, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(Conv2D(48, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1164))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "hist = model.fit_generator(train_gen, steps_per_epoch=EPOCH_STEPS, verbose=1, validation_data = valid_gen, validation_steps=VALID_STEPS, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
